
<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
body, html {
  height: 100%;
  margin: 0;
  font: 400 15px/1.8 "Lato", sans-serif;
  color: #777;
}

a:link {
  color: rgb(201, 178, 5);
  background-color: transparent;
  text-decoration: none;
}

a:visited {
  color: rgb(70, 5, 201);
  background-color: transparent;
  text-decoration: none;
}

.bgimg-1, .bgimg-2, .bgimg-3, .bgimg-4 {
  position: relative;
  opacity: 0.65;
  background-attachment: fixed;
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;

}
.bgimg-1 {
  background-image: url("https://www.intotheminds.com/blog/app/uploads/desk-research-group-tn.jpg");
  min-height: 20%;
}

.caption {
  position: absolute;
  left: 0;
  top: 50%;
  width: 100%;
  text-align: center;
  color: #000;
}

.caption span.border {
  background-color: #111;
  color: #fff;
  padding: 18px;
  font-size: 25px;
  letter-spacing: 10px;
}

h3 {
  letter-spacing: 5px;
  text-transform: uppercase;
  font: 20px "Lato", sans-serif;
  color: #111;
}

/* Turn off parallax scrolling for tablets and phones */
@media only screen and (max-device-width: 1024px) {
  .bgimg-1, .bgimg-2, .bgimg-3 {
    background-attachment: scroll;
  }
}
</style>
</head>
<body>


<div style="position:relative;">
  <div style="color:#282E34;background-color:white;text-align:left;padding:50px 80px;">
    <h3 style="text-align:left;color:rgb(164, 162, 6);">Project Contributors</h3>
    <iframe src="./contributors.txt" width="90%" height="300px" frameborder="0%" id="contributors_frame" scrolling="yes"></iframe>
</div>

<div style="position:relative;">
  <div style="color:white;background-color:#03396f;text-align:left;padding:50px 80px;">
    <h3 style="text-align:center;color:lightslategrey;">Works Cited</h3>
    <p>Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ü¶ú. Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 610‚Äì623. https://doi.org/10.1145/3442188.3445922</p>
    <p>Bender, E. M., & Koller, A. (2020). Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data. In D. Jurafsky, J. Chai, N. Schluter, & J. Tetreault (Eds.), Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (pp. 5185‚Äì5198). Association for Computational Linguistics. https://doi.org/10.18653/v1/2020.acl-main.463</p>
    <p>Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., & Stoyanov, V. (2019). RoBERTa: A Robustly Optimized BERT Pretraining Approach (arXiv:1907.11692). arXiv. https://doi.org/10.48550/arXiv.1907.11692</p>
    <p>Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient Estimation of Word Representations in Vector Space. Arxiv.</p>
    <p>Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv:1810.04805 [Cs]. http://arxiv.org/abs/1810.04805</p>
    <p>Rosen, Z. P., & Dale, R. (2023). BERTs of a feather: Studying inter- and intra-group communication via information theory and language models. Behavior Research Methods. https://doi.org/10.3758/s13428-023-02267-2</p>
    <p>Rosen, Z. P., & Dale, R. (2024). LLMs Don‚Äôt ‚ÄúDo Things with Words‚Äù but Their Lack of Illocution Can Inform the Study of Human Discourse. Proceedings of the Annual Meeting of the Cognitive Science Society, 46(0). https://escholarship.org/uc/item/25k7z0mz</p>
    <p>Titus, L. M. (2024). Does ChatGPT have semantic understanding? A problem with the statistics-of-occurrence strategy. Cognitive Systems Research, 83, 101174. https://doi.org/10.1016/j.cogsys.2023.101174</p>
    <p>Utsumi, A. (2020). Exploring What Is Encoded in Distributional Word Vectors: A Neurobiologically Motivated Analysis. Cognitive Science, 44(6), e12844. https://doi.org/10.1111/cogs.12844</p>
    <p>Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., & Ga≈°eviƒá, D. (2024). Practical and ethical challenges of large language models in education: A systematic scoping review. British Journal of Educational Technology, 55(1), 90‚Äì112. https://doi.org/10.1111/bjet.13370</p>
  </div>
</div>

</body>
</html>